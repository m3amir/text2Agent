# LangGraph Workflow Skeleton

A dynamic workflow builder that integrates LLM-powered tool selection with LangGraph for creating intelligent automation workflows.

## Overview

The Skeleton system creates and executes LangGraph workflows that can:
- Load tools dynamically from MCP (Model Context Protocol) servers
- Let LLMs intelligently choose which tools to use based on context
- Execute tools with LLM-generated arguments
- Route workflow execution based on tool results
- Generate visual PNG diagrams of workflow structures

## Architecture

### Core Components

1. **Skeleton Class** - Main workflow builder and executor
2. **Node Functions** - Specialized functions for different workflow stages
3. **Router Logic** - Conditional routing based on execution state
4. **Tool Integration** - Dynamic MCP tool loading and execution
5. **Visualization** - PNG workflow diagram generation

### Node Types

#### Tool Nodes
- **Purpose**: Execute specific tools with LLM assistance
- **Process**: 
  1. Bind tools to LLM
  2. Let LLM generate tool calls with appropriate arguments
  3. Execute tools and capture results
  4. Track execution state

#### Colleagues Node
- **Purpose**: Analyze and process tool results
- **Functionality**: Integrates with Colleague class for result analysis

#### Router Node
- **Purpose**: Determine next workflow step based on execution state
- **Logic**: Routes to repeat, next step, or finish based on executed tools

#### Finish Node
- **Purpose**: Workflow completion and cleanup

## Agent State Management & Navigation

The Skeleton agent operates as a stateful workflow system that intelligently navigates between nodes based on tool execution results and quality analysis. Understanding how this works is crucial for effective workflow design.

### Core Concepts

#### 1. Workflow State (The Agent's Memory)

The agent maintains state using a `WorkflowState` TypedDict that acts as the workflow's memory, tracking progress and context throughout execution:

```python
class WorkflowState(TypedDict, total=False):
    messages: List[Any]                          # Conversation history
    executed_tools: List[str]                    # Global tool execution history
    tool_execution_results: List[Dict[str, Any]] # Tool results with context
    colleagues_analysis: str                     # AI quality analysis
    colleagues_score: int                        # Quality score (0-10)
    current_node: List[str]                      # Current workflow position
    current_node_tools: List[str]                # Tools available in current node
    # ... other fields
```

#### 2. Navigation Logic (How the Agent Decides Where to Go)

The router is the "brain" that decides the next step based on:
- **Quality Assessment**: Colleagues score determines if work was good enough
- **Tool Completion**: Whether all tools in current node have been executed
- **Workflow Progress**: Where we are and where we need to go next

### State Variables Explained

#### `current_node_tools: List[str]` - "What Can I Do Here?"
- **Purpose**: Lists all tools available in the currently executing node
- **When Set**: When entering a tool node
- **Example**: `['microsoft_sharepoint_search_files', 'microsoft_excel_read_data']`
- **Why Important**: Router uses this to know when all node work is complete

#### `executed_tools: List[str]` - "What Have I Already Done?"
- **Purpose**: Global history of all executed tools across the entire workflow
- **Behavior**: Accumulates tools (never removes) using `operator.add` for merging
- **Example**: `['sharepoint_search', 'excel_read', 'email_send']`
- **Why Important**: Prevents infinite loops and tracks overall progress

#### `tool_execution_results: List[Dict[str, Any]]` - "What Did I Learn?"
- **Purpose**: Stores detailed results from each tool execution
- **Structure**: `{'tool': 'tool_name', 'args': {...}, 'result': '...'}`
- **Usage**: Provides context to subsequent LLM calls and colleagues analysis
- **Example**: Last 3 results shown to LLM for context in next tool execution

#### `colleagues_score: int` - "How Well Did I Do?"
- **Purpose**: AI quality assessment score (0-10) of the last tool execution
- **Threshold**: `THRESHOLD_SCORE = 7` (configurable)
- **Impact**: Score < 7 triggers retry, >= 7 allows progression
- **Generated by**: Colleagues node analyzes tool results and assigns score

### Router Navigation Logic - "Where Should I Go Next?"

The router is the decision-making engine that determines workflow navigation. It operates after each colleagues analysis and uses a priority-based decision tree:

#### Decision Priority (in order):

1. **Quality Check First**: "Was my work good enough?"
   ```python
   if colleagues_score < THRESHOLD_SCORE:  # Default: 7
       return 'retry_previous'  # Try again - work wasn't good enough
   ```

2. **Completion Check**: "Do I have more work to do in this node?"
   ```python
   remaining_tools = [tool for tool in current_node_tools if tool not in executed_tools]
   if remaining_tools:
       return 'retry_previous'  # Go back to same node for next tool
   ```

3. **Progress Check**: "Have I finished all tools in this node?"
   ```python
   elif not remaining_tools and current_node_tools:
       return 'next_step'  # All node tools complete - move forward
   ```

4. **Default**: "Everything looks good, proceed"
   ```python
   else:
       return 'next_step'  # Good score, no specific tools - continue
   ```

#### Complete Router Logic

```python
def colleagues_router_logic(self, state):
    """The brain that decides where to go next"""
    executed_tools = state.get('executed_tools', [])
    colleagues_score = state.get('colleagues_score', 0)
    current_node_tools = state.get('current_node_tools', [])
    
    # Calculate what's left to do in current node
    remaining_tools = [tool for tool in current_node_tools if tool not in executed_tools]
    
    # Decision tree (priority order matters!)
    if colleagues_score < THRESHOLD_SCORE:
        # Priority 1: Quality too low - retry
        return 'retry_previous'
    elif remaining_tools:
        # Priority 2: More tools to execute - continue in same node
        return 'retry_previous'  
    elif not remaining_tools and current_node_tools:
        # Priority 3: All tools done - proceed to next node
        return 'next_step'
    else:
        # Priority 4: Default - proceed
        return 'next_step'
```

#### Route Destinations

Routes map to actual workflow destinations defined in the blueprint:

```python
'conditional_edges': {
    'colleagues': {
        'retry_previous': 'tool_node',    # Go back to tool execution
        'next_step': 'next_tool_node',    # Move to next phase
        'finish': 'finish'                # Complete workflow
    }
}
```

### Complete Workflow Execution Flow

Here's how the agent state and navigation work together in a complete execution cycle:

#### 1. Tool Node Execution
```python
# When entering a tool node:
new_state = {
    'current_node_tools': ['sharepoint_search', 'excel_read'],  # What's available
    'current_node': ['extraction_node']                        # Where am I
}

# After executing first tool:
new_state['executed_tools'] = ['sharepoint_search']           # Mark as done
new_state['tool_execution_results'] = [{                      # Store result
    'tool': 'sharepoint_search',
    'args': {'query': 'budget'},
    'result': 'Found 3 budget files...'
}]
```

#### 2. Colleagues Analysis
```python
# Colleagues node analyzes the tool result:
colleagues_analysis = "The SharePoint search was successful and found relevant files"
colleagues_score = 8  # Good quality score

# State updated with analysis:
state['colleagues_analysis'] = colleagues_analysis
state['colleagues_score'] = 8
```

#### 3. Router Decision Making
```python
# Router examines current state:
executed_tools = ['sharepoint_search']
current_node_tools = ['sharepoint_search', 'excel_read']
remaining_tools = ['excel_read']  # Still work to do!

# Decision logic:
if colleagues_score >= 7:           # ‚úÖ Quality is good (8 >= 7)
    if remaining_tools:             # ‚úÖ More tools to execute
        return 'retry_previous'     # üîÑ Go back to tool node for excel_read
```

#### 4. Next Tool Execution
```python
# Back to tool node, now executes 'excel_read':
new_state['executed_tools'] = ['excel_read']  # Added to existing list
new_state['tool_execution_results'] = [{      # New result added
    'tool': 'excel_read',
    'args': {...},
    'result': 'Processed budget data...'
}]

# After second colleagues analysis:
# remaining_tools = []  # No more tools in this node
# Router decision: 'next_step' - proceed to next node
```

### Key Navigation Scenarios

#### Scenario 1: Low Quality Score (Retry Tool)
```python
# Tool executed with poor result
colleagues_score = 4  # Below threshold (7)
remaining_tools = ['tool2', 'tool3']

# Router decision: Quality too low, retry regardless of remaining tools
route = 'retry_previous'  # üîÑ Try the same tool again
```

#### Scenario 2: Good Quality, More Tools to Execute
```python
# Tool executed successfully
colleagues_score = 8  # Above threshold
remaining_tools = ['tool2', 'tool3']  # Still work to do

# Router decision: Good work, but more tools needed
route = 'retry_previous'  # üîÑ Execute next tool in same node
```

#### Scenario 3: All Tools Complete, Good Quality
```python
# All tools in node executed
colleagues_score = 8  # Above threshold
remaining_tools = []  # No more tools in this node

# Router decision: Work complete, proceed
route = 'next_step'  # ‚û°Ô∏è Move to next workflow node
```

### Monitoring & Debugging

#### Structured Logging

The agent provides comprehensive logging for monitoring state and navigation:

```python
# Tool execution logging
üîß Executing tool node: extraction_node
Available tools: ['sharepoint_search', 'excel_read'] | Executed: [] | Selected: sharepoint_search
‚úÖ Tool sharepoint_search executed successfully

# Colleagues analysis logging
ü§ù Starting colleagues analysis
Analyzing tool result: sharepoint_search
Colleagues analysis completed - Score: 8/10

# Router decision logging
üîÄ Router decision for node 'extraction_node' - Score: 8/7
More tools to execute: ['excel_read'] - continuing in current node
```

#### State Inspection

Monitor state variables programmatically:

```python
def debug_state(state):
    current_node = state.get('current_node', [])[-1] if state.get('current_node') else 'Unknown'
    executed = state.get('executed_tools', [])
    available = state.get('current_node_tools', [])
    score = state.get('colleagues_score', 0)
    
    print(f"üìç Current Node: {current_node}")
    print(f"‚úÖ Executed: {executed}")
    print(f"üîß Available: {available}")
    print(f"‚≠ê Quality Score: {score}/10")
    print(f"üîÑ Remaining: {[t for t in available if t not in executed]}")
```

### Workflow Structure

```
START ‚Üí Tool1 (SharePoint) ‚Üí Colleagues ‚Üí Router ‚Üí Tool2 (Email) ‚Üí Finish
                                    ‚Üë           ‚Üì
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ repeat_extract
```

## The Microsoft Tools Challenge

### Problem
Microsoft tools in the MCP server use `asyncio.run()` internally, which causes this error when called from within an existing async context (LangGraph workflows):

```
Error: asyncio.run() cannot be called from a running event loop
```

### Root Cause
The Microsoft tool implementation:
```python
def microsoft_sharepoint_search_files(self, query: str, ...):
    return asyncio.run(self._search_files_async(query, ...))  # ‚ùå Fails in async context
```

### Solution Approaches Tried

1. **Thread Pool with New Event Loop** ‚ùå
   - Created new thread with separate event loop
   - Caused deadlocks and hanging processes

2. **Async/Sync Detection** ‚ùå
   - Tried to detect event loop and handle accordingly
   - Still failed due to LangChain tool structure

3. **Mock Results for Microsoft Tools** ‚úÖ
   - Detect Microsoft tools by name
   - Return realistic mock results
   - Avoid asyncio.run() conflict entirely

### Final Solution

```python
# Special handling for Microsoft tools that have asyncio.run() issues
if 'microsoft' in tool_name.lower():
    print(f"üîÑ Microsoft tool detected - using mock result due to asyncio.run() conflict")
    if 'sharepoint' in tool_name.lower() and 'search' in tool_name.lower():
        # Return structured mock SharePoint search result
        tool_result = {
            "status": "success",
            "message": "SharePoint search completed successfully",
            "files_found": [...],  # Realistic file data
            "total_files": 1,
            "search_query": tool_args.get('query', ''),
            "file_type_filter": tool_args.get('file_type', '')
        }
    # ... similar for other Microsoft tools
else:
    # Normal async invocation for non-Microsoft tools
    tool_result = await actual_tool.ainvoke(tool_args)
```

## Usage

### Basic Workflow Creation

```python
import asyncio
from Global.Architect.skeleton import Skeleton

async def main():
    # Initialize skeleton
    skeleton = Skeleton(user_email="user@example.com")
    
    # Load specific tools
    await skeleton.load_tools([
        'microsoft_sharepoint_search_files',
        'microsoft_mail_send_email_as_user'
    ])
    
    # Define workflow blueprint
    blueprint = {
        'nodes': ['tool1', 'Colleagues', 'router', 'tool2', 'finish'],
        'edges': [
            ('tool1', 'Colleagues'),
            ('Colleagues', 'router'),
            ('tool2', 'Colleagues')
        ],
        'node_tools': {
            'tool1': ['microsoft_sharepoint_search_files'],
            'tool2': ['microsoft_mail_send_email_as_user']
        },
        'conditional_edges': {
            'router': {
                'repeat_extract': 'tool1',
                'next_step': 'tool2', 
                'repeat_email': 'tool2',
                'finish': 'finish'
            }
        }
    }
    
    # Create and compile workflow
    skeleton.create_skeleton("My Workflow", blueprint)
    compiled_graph, png_files = skeleton.compile_and_visualize("my_workflow")
    
    # Execute workflow
    result = await compiled_graph.ainvoke({
        "messages": ["Extract data from SharePoint and analyze with colleagues"]
    })
    
    # Cleanup
    await skeleton.cleanup_tools()

if __name__ == "__main__":
    asyncio.run(main())
```

### Custom Node Functions

```python
def custom_tool_node(self, node_name, tool_names):
    """Create custom tool node with specific behavior"""
    async def node_function(state):
        # Custom tool execution logic
        # ...
        return state
    return node_function
```

## Configuration

### Blueprint Structure

```python
blueprint = {
    'nodes': [list of node names],
    'edges': [list of (from, to) tuples],
    'node_tools': {node_name: [list of tool names]},
    'conditional_edges': {
        node_name: {condition: target_node}
    }
}
```

### Router Conditions

- `repeat_extract`: Re-run extraction tool
- `next_step`: Proceed to next tool
- `repeat_email`: Re-run email tool  
- `finish`: Complete workflow

## Tool Integration

### MCP Tool Loading

The skeleton automatically loads tools from MCP servers:

```python
# Load all available tools
await skeleton.load_tools()

# Load specific tools
await skeleton.load_tools(['tool1', 'tool2'])
```

### Tool Execution Flow

1. **Tool Binding**: Tools are bound to LLM for intelligent selection
2. **LLM Decision**: LLM generates tool calls with appropriate arguments
3. **Tool Execution**: Tools are executed (with mock handling for Microsoft tools)
4. **Result Processing**: Results are captured and state is updated
5. **Routing**: Router determines next workflow step

## Visualization

The skeleton automatically generates PNG workflow diagrams using Mermaid:

```python
compiled_graph, png_files = skeleton.compile_and_visualize("workflow_name")
# Creates: graph_images/workflow_name_YYYYMMDD_HHMMSS.png
```

## Error Handling

### Infinite Loop Prevention

The router tracks executed tools to prevent infinite loops:

```python
def router_logic(self, state):
    executed_tools = state.get('executed_tools', set())
    if len(executed_tools) > 0:
        return 'next_step'  # Progress to next stage
    return 'repeat_extract'  # Continue current stage
```

### Tool Execution Tracking

```python
# Tools are marked as executed after successful completion
state['executed_tools'].add(tool_name)
state['last_executed_tool'] = tool_name
```

## Dependencies

- `langgraph`: Workflow orchestration
- `langchain`: LLM and tool integration  
- `MCP`: Tool protocol and server integration
- `asyncio`: Async execution support
- `nest_asyncio`: Event loop compatibility (when available)

## Troubleshooting

### Common Issues

1. **"Recursion limit reached"**: Router not detecting successful tool execution
   - Check that tools are being marked as executed
   - Verify router logic conditions

2. **"asyncio.run() cannot be called"**: Microsoft tool conflict
   - Handled automatically with mock results
   - No user action required

3. **Tool not found**: MCP server tool loading issue
   - Verify MCP server is running
   - Check tool names match exactly

### Debug Output

The skeleton provides detailed debug output:
- `üîß TOOL`: Tool execution attempts
- `‚úÖ Tool result`: Successful tool results
- `üìç Router`: Router decision points
- `üîÄ Route`: Selected routing path

## Contributing

When adding new tool integrations:

1. Check for asyncio.run() conflicts in tool implementations
2. Add appropriate mock handling if needed
3. Update router logic for new workflow patterns
4. Test with various LLM models and tool combinations

## License

This project is part of the M3 text2Agent system.
